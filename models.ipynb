{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxDhPT1aa+OVIjm1A+i0Z1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ORB-mTcI0K0N"},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"code","source":["# real image segmentation U-Net model\n","# for image size of 288x288\n","class imgsegUnet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.step_down_1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_4 = nn.Sequential(\n","            nn.Conv2d(128, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(3,3), stride=3)\n","        )\n","\n","\n","        self.step_up_4 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 128, kernel_size=(3,3), stride=3)\n","        )\n","\n","        new_channels = 128+128\n","\n","        self.step_up_3 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(128, 128, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 128+64\n","\n","        self.step_up_2 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 64+64\n","\n","        self.step_up_1 = nn.Sequential(\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        self.class_predictions_block = nn.Sequential(\n","            nn.Conv2d(64, 16, kernel_size = (3,3), padding = 1),\n","            nn.Conv2d(16, out_channels, kernel_size = (3,3), padding = 1)\n","        )\n","\n","        self.drop = nn.Dropout2d(p=0.1)\n","\n","\n","    def forward(self, x):\n","\n","        output = self.step_down_1(x)\n","        skip_1 = output\n","\n","        output = self.step_down_2(output)\n","        skip_2 = output\n","\n","        output = self.step_down_3(output)\n","        skip_3 = output\n","\n","        output = self.step_down_4(output)\n","\n","        output = self.drop(output)\n","\n","        output = self.step_up_4(output)\n","        output = torch.cat((output, skip_3), dim=1)\n","\n","        output = self.step_up_3(output)\n","        output = torch.cat((output, skip_2), dim=1)\n","\n","        output = self.step_up_2(output)\n","        output = torch.cat((output, skip_1), dim=1)\n","\n","        output = self.step_up_1(output)\n","\n","        output = self.drop(output)\n","\n","        output = self.class_predictions_block(output)\n","\n","        return output"],"metadata":{"id":"XSej1P7VH6OH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# real image segmentation U-Net model mach 2\n","# for image size of 288x288\n","class imgSegUnet_m2(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.step_down_1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(3,3), stride=3)\n","        )\n","\n","\n","        self.step_up_4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 128, kernel_size=(3,3), stride=3)\n","        )\n","\n","        new_channels = 128+128\n","\n","        self.step_up_3 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(128, 128, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 128+64\n","\n","        self.step_up_2 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 64+64\n","\n","        self.step_up_1 = nn.Sequential(\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        self.class_predictions_block = nn.Sequential(\n","            nn.Conv2d(64, 16, kernel_size = (3,3), padding = 1),\n","            nn.Conv2d(16, out_channels, kernel_size = (3,3), padding = 1)\n","        )\n","\n","        self.drop = nn.Dropout2d(p=0.1)\n","\n","\n","    def forward(self, x):\n","\n","        output = self.step_down_1(x)\n","        skip_1 = output\n","\n","        output = self.step_down_2(output)\n","        skip_2 = output\n","\n","        output = self.step_down_3(output)\n","        skip_3 = output\n","\n","        output = self.step_down_4(output)\n","\n","        output = self.drop(output)\n","\n","        output = self.step_up_4(output)\n","        output = torch.cat((output, skip_3), dim=1)\n","\n","        output = self.step_up_3(output)\n","        output = torch.cat((output, skip_2), dim=1)\n","\n","        output = self.step_up_2(output)\n","        output = torch.cat((output, skip_1), dim=1)\n","\n","        output = self.step_up_1(output)\n","\n","        output = self.drop(output)\n","\n","        output = self.class_predictions_block(output)\n","\n","        return output"],"metadata":{"id":"fsZrp7FBPaak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Not the right implementation, output channels is set to 1 always at the end, I don't use the 'out_channels' parameter.\n","# Only keeping it because one model uses this and I trained it a bunch and it works because it needs out_channels=1\n","\n","class image_seg_UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.step_down_1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(2,2), stride=2)\n","        )\n","\n","        self.step_down_4 = nn.Sequential(\n","            nn.Conv2d(128, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=(3,3), stride=3)\n","        )\n","\n","\n","        self.step_up_4 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 128, kernel_size=(3,3), stride=3)\n","        )\n","\n","        new_channels = 128+128\n","\n","        self.step_up_3 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 128, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(128, 128, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 128+64\n","\n","        self.step_up_2 = nn.Sequential(\n","            nn.Conv2d(new_channels, new_channels, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        new_channels = 64+64\n","\n","        self.step_up_1 = nn.Sequential(\n","            nn.Conv2d(new_channels, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(64, 64, kernel_size=(3,3), padding = 1),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(64, 64, kernel_size=(2,2), stride = 2),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        self.class_predictions_block = nn.Sequential(\n","            nn.Conv2d(64, 16, kernel_size = (3,3), padding = 1),\n","            nn.Conv2d(16, 1, kernel_size = (3,3), padding = 1)\n","        )\n","\n","\n","    def forward(self, x):\n","\n","        output = self.step_down_1(x)\n","        skip_1 = output\n","\n","        output = self.step_down_2(output)\n","        skip_2 = output\n","\n","        output = self.step_down_3(output)\n","        skip_3 = output\n","\n","        output = self.step_down_4(output)\n","\n","        output = self.step_up_4(output)\n","        output = torch.cat((output, skip_3), dim=1)\n","\n","        output = self.step_up_3(output)\n","        output = torch.cat((output, skip_2), dim=1)\n","\n","        output = self.step_up_2(output)\n","        output = torch.cat((output, skip_1), dim=1)\n","\n","        output = self.step_up_1(output)\n","\n","        output = self.class_predictions_block(output)\n","\n","        return output"],"metadata":{"id":"YlDy-7UY0Oek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"_RkScqO70sEY"},"execution_count":null,"outputs":[]}]}